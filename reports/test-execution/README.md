# Test Execution Reports

This directory contains structured test execution reports (TER) generated by the LLMHub test runner.

## Report Format

Each test run produces:
- `TER-YYYYMMDD-HHMM-<short_sha>.json` - Structured JSON report
- `TER-YYYYMMDD-HHMM-<short_sha>.md` - Human-readable Markdown summary

## JSON Schema

```json
{
  "project": "llm-hub",
  "run_id": "TER-20241129-1430-abc1234",
  "commit": "abc1234567890...",
  "branch": "main",
  "timestamp": "2024-11-29T14:30:00",
  "environment": {
    "python_version": "3.11.5",
    "os": "Darwin 23.0.0",
    "llmhub_version": "0.1.0"
  },
  "summary": {
    "total_tests": 25,
    "passed": 23,
    "failed": 2,
    "skipped": 0,
    "errors": 0,
    "duration_seconds": 12.345,
    "status": "failed"
  },
  "suites": [
    {
      "name": "test_suite_name",
      "path": "packages/llmhub/tests/test_example.py",
      "summary": { ... },
      "tests": [
        {
          "id": "test_module::test_function",
          "name": "test_function",
          "status": "passed",
          "duration_seconds": 0.123,
          "tags": [],
          "error": null
        }
      ]
    }
  ]
}
```

## Generating Reports

```bash
# Run tests with report generation
python -m llmhub.tools.run_tests_with_report
```

## Interpreting Reports

- **Status**: `passed` (all tests passed), `failed` (one or more failures), or `error` (test suite error)
- **Summary**: High-level counts and duration
- **Suites**: Per-suite breakdown with individual test results
- **Error details**: Available for failed/error tests in the `error` field
